# Tokenizing Of Source Code



In this step we will use the Flex tool, a GNU project. Basically, this process can be described as breaking down user-written source code into tokens (the smallest building blocks of a programming language).

Since this language will be constantly updated, tokens will be listed here after each release. In order to understand the operations in this step, you should have a basic understanding of regular expressions, average C programming knowledge and the ability to use the Flex tool.




## What is Flex?

Flex (Fast Lexical Analyzer) is a tool for generating scanners: programs that recognize lexical patterns in text. It reads a set of rules written by the user (in regular expressions) and converts them into a C program that efficiently recognizes tokens in source code.

Flex is commonly used in compilers and interpreters to convert user-written code into tokens, which are the smallest building blocks of the programming language (such as keywords, operators, identifiers, and numbers).



## The Tokenizing Process

In the tokenizing process, the source code written by users is broken down into individual tokens. These tokens include keywords, operators, variable names, numbers, and other syntactical elements of the language. The lexical analyzer (scanner) generated by Flex will take the input source code and output a sequence of tokens, which can be further processed by the parser.

For example, in a simple expression like `a = b + 5;`, Flex will generate tokens for the variable names (`a` and `b`), the operator (`=`), the plus operator (`+`), and the number (`5`).



## Contributing to the Tokenization Process

If you wish to contribute to the tokenization process of this language, you will need a basic understanding of regular expressions and the Flex tool. Hereâ€™s how you can get started:

1. Install Flex: You can install Flex on your machine using package managers like `apt`, `yum`, or `brew` depending on your operating system.
2. Clone the repository: 
   ```bash
   git clone https://github.com/A-proglang.git
   cd A-proglang
   ```
3. Define your tokens: Add your new tokens in the Flex definition file (`lexer.l`), using regular expressions to specify the patterns.
4. Test your changes: Run Flex to generate the scanner and test the new tokens on sample code.

Contributions should include clear and concise commit messages explaining what tokens were added or modified.



## Testing Your Changes

After adding or modifying tokens, you can test the tokenization process by providing a sample input file. Here's a basic example:

```bash
flex lexer.l
gcc lex.yy.c -o scanner
./scanner < sample_code.txt

# or

./scanner # for REPL
```

